---
title: Skyplane 浅述
date: 2022-10-08 14:38:30
categories: 'Networking'
tags:
	- '云计算'
---

[skyplane-project / skyplane](https://github.com/skyplane-project/skyplane)

<!-- more -->

这几天在看算力网络相关的东西，老师让调研一下 Skyplane，于是花时间看了一下。

## Intro

Skyplane 是一个云上的超大数据的同步器。它可以管理并行化传输，数据分割，优化传输网路，并启动多 VM 提高吞吐量。

使用 Skyplane 可以在如下服务之间传递数据：

- 在云服务商内部，比如 S3 到 S3
- 从多云服务商，比如 S3 到 Azure
- 在本地和云服务商之间

## Motivation

二十世纪九十年代中期有了 Web 托管服务，但是需要按 CPU，内存，带宽，存储分别付费。这就很烦，于是就有了 AWS 这样的云服务，他们打包了一套计算资源，但是在付费方面开倒车。

---

如果是一个在云上开发过什么东西并且上过线的话可能会比较理解，就比如腾讯云会卖两种服务器，一种是 CVM，一种是 Lighthouse。CVM 是类似 EC2 的那种稳定性比较高的服务器，Lighthouse 也就是所谓轻量级服务器。CVM 的带宽特别低，一般只有 1M，Lighthouse 可以有 8M 或者 10M 的带宽。但是 CVM 支持按量付费，Lighthouse 是开箱即用的，可以预装各种环境，比如 LAMP 啥的，腾讯云可以预装宝塔（乐）。

但是它们都有一个缺点就是~~贼他吗~~贵，贵得离谱，贵得吓人，贵得没有底线。CVM 包月服务加带宽可能会加到上万一个月，按量计费加带宽比较便宜，但是也就局限于开一两天。我们校赛在华为云开按量计费，10M 的带宽开一天也要一百多块钱。

但是作为 Web 服务最重要的就是保证带宽，1M 小水管 P 用没有，把前端放在服务器上就会变成灾难，10 用户甚至 9 用户并发下一些前端大 JS 就会卡住。

---

诸如 AWS 的云服务是向用户存储收费的，但是他们又要为修机房建网络付钱，通过 [Cloudflare 的调查](https://blog.cloudflare.com/aws-egregious-egress/)发现，北美地区用户为数据存储付的钱是 AWS 为网络带宽付的钱的 80 倍。这就造成了一种不平等。

现在有了机器学习，我们为了经济，可能在 AWS 的 S3 上开存储，在 GCP 的计算中心学习，然后把模型发布到 Azure 上让其他人用。这里就涉及了大量的数据传递，比如把训练数据跨云服务商传递，或者在数据中心之间传递数据。

研究者调研了一些云服务商，发现他们的出口流量小，费用高，导致云上串行化组织困难。并且云服务商均使用 [hot-potato routing](https://en.wikipedia.org/wiki/Hot-potato_and_cold-potato_routing)，即将流量尽可能快地转发给下个自治域。例如云 A 的北美节点向云 B 的亚洲节点运输，使用 hot-potato routing 的话云 A 会把数据丢给云 B 的北美节点，然后云 B 内部将数据传给亚洲节点。这样对于 A 来说的花费是最小的，因为 A 不需要满世界建节点，但是最终速度是取决于云服务商的美洲节点之间互联的速度的，所以作者的结论是云服务商会优化花费，但不是速度。

## Sky Computing

近些年以 UC Berkeley 为代表的实验室提出了 Sky Computing 的概念，不知道该咋翻译，总不能直接称为天计算吧，总之他们是想把这些云服务商连起来，构造另一个顶层逻辑。

现在 Sky Computing 的瓶颈就在于各个云服务商提供的出口流量太小了，在 IO 密集型需求上就只能在一个 DC 内部做，如果跨 DC 就需要网络交互，而云服务商的出口流量正限制了这一业务。所以期望找到一个什么架构去连接这些云，使它们成为一个整体进行调度。

## Method

Skyplane 是为了解决这一问题设计的。它的工作步骤如下：

1. 首先检查要传输数据的源和目的的 diff
2. 选择一个传输方案，使得达到最小花费和最大吞吐量
3. 启动多个 VM 进行并行传输

第三点中使用多个 VM 为的是并行化，VM 可以使用多块网卡同时传输数据。选路的时候优化的是吞吐量而非延迟，所以找到最大吞吐的路由是目标。有些延迟较高的路吞吐量也很高，在路由的时候也会考虑这些路径。

在代码中，延迟和吞吐量数据都是预先测量好的，在代码里只是计算用。

## Comment

首先看了一眼作者的研究方向，是 ML System，感觉和 Network 不太沾边。这个系统的后期工作中倒是包括优化机器学习的学习过程和部署。

整个系统是通过优化选路和并行来提高吞吐量的，其实也没做什么协议的改变，整个东西还是架在应用层的。但是确实避免了 hot-potato routing，最优选吞吐量大的来获得性能提升，这个部分可以做个 SDN。

但是两点之间吞吐量和延迟可能是动态变化的，最优选路也是动态的。怎么抑制这样的路由摆动可能需要注意。
