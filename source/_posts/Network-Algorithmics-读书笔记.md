---
title: Network Algorithmics 读书笔记
date: 2023-02-22 22:16:21
categories: 'Networking'
tags:
	- '笔记'
description: ' '
---

老板让我看两本书：[Network Algorithmics](https://www.elsevier.com/books/network-algorithmics/varghese/978-0-12-809927-8) 和 [High Performance Switches and Routers](https://ieeexplore.ieee.org/book/5236680)，搜了一下发现后一本书比较老，~~并且亚马逊上书评（两条）不怎么好~~，所以先看第一本了。

但是全英的，边看还要边复习英语，虽然也看过翻译过不少英文题，但还是有点崩溃。争取一天看一点，一周一更吧。

实际上中科大开了这门课：[网络算法学](http://staff.ustc.edu.cn/~bhua/)，但是只有前九章，也就是前两个部分，有课件但是没有课程录像什么的。Harvey Mudd College 也开了这门课：[CS181AG](https://www.cs.hmc.edu/~apadmanabhan/cs181ag-F22/)，有课程录像和课件，但是是英文的，还是看书吧……

> 个人评论用引用表达，就像这句话这样。个人观点可能有失偏颇，并且可能修改，请勿引用。

## 前言

网络瓶颈（*network bottlenecks*）是影响网络性能的主要因素之一。有两种瓶颈：资源瓶颈（*resource bottlenecks*）和实现瓶颈（*implementation bottlenecks*）。

资源瓶颈指底层硬件受限，比如处理器速度慢，通讯连接慢等等。但资源瓶颈可以灵活处理，花钱就能变强。

主要问题是实现瓶颈，下层硬件资源甚至是冗余的，上层程序跑得依然很慢。本书关心的就是这种瓶颈，特别是在服务器和路由器上的实现瓶颈。

本书旨在提供在所有网络上都能克服实现瓶颈的技术，并提供能够克服现在和未来网络瓶颈的准则和模型。

网络算法学（*network algorithmics*）是跨学科的，需要体系结构，操作系统，硬件设计和算法知识。网络算法学也是一个系统性的方法。

> 网络算法学这个名字是直译的，但是一些图论算法也被叫做 network algorithmics，我不确定是不是有更好的译名，只是遵从中科大课程的名字。但是可以肯定的是，网络算法学不仅包括算法，还糅合了实现黑魔法，不属于严格意义上的算法学研究领域。个人认为分为两部分：属于算法学研究的领域，和更高阶的算法实现技术（或技巧）。

本质上，本书讨论三件事：

- 基本的网络实现瓶颈
  - PC 或服务器的瓶颈包括：数据复制，控制传输，多路复用，计时器，缓存分配，校验和和协议处理；
  - 互联设备的瓶颈包括：前缀查询和精确查询，包分类，交换，测量实现和权限安全实现。
- 解决新瓶颈的基本原则
- 从基本原则出发，解决特殊瓶颈的方法

### 15 个解决网络瓶颈的原则

> 详细的解释在后面的章节，这里先补个课。

1. 避免明显的浪费（*Avoid obvious waste*）

   - [零拷贝接口](https://en.wikipedia.org/wiki/Zero-copy)（*Zero-copy interfaces*）

     > 目前零拷贝是一个十分通用的技术了，可以看 [netpoll](https://github.com/cloudwego/netpoll) 的实现。

2. 将计算变为时间（*Shift computation in time*）

   > 关于这个原则的翻译我不好说，这个原则和原则 3.3. 的形式一致，但是翻译过来就怪怪的。这个原则主要针对一些可合并的操作，采用一些方式降低处理数据的时间消耗。

   1. 预处理（*Precompute*）

      - 应用设备通道（*Application device channels*）

        > 网上并没有什么介绍，我没听说过也不知道这是什么……

   2. 惰性计算（*Evaluate lazily*）

      - [写时复制](https://en.wikipedia.org/wiki/Copy-on-write)（*Copy-on-write*）

        > 这也是一个比较通用的技术了，netpoll 的实现中也有，在无锁编程里也有这样的思想。其实和线段树 lazy tag 一样，用的时候再传标记。不过也是看场景使用。

   3. 共享代价和批次（*Share expenses, batch*）

      - [集成层处理](https://wiki.c2.com/?IntegratedLayerProcessing)（*Integrated layer processing*）

        > 因为把协议软件分层会导致性能降低，层之间不能容易地分享信息，这些层可能记录了冗余信息，协议头就会变大。因此可以选择把这些层整合成一层。RTP 协议是以这个原则设计的。但是这样直接打破了网络体系结构，我觉得可能是可以的，但是我不好说。关于翻译，由于多层共享同一个报文，处理报文的代价是共享的，处理时段是相同的，是谓共享代价和批次。

3. 放松系统需求（*Relax system requirements*）

   1. 用确定性换时间（*Trade certainty for time*）

      - [随机公平队列](https://www.researchgate.net/publication/2411061_Stochastic_Fairness_Queuing)（*Stochastic fair queueing*）

        > 我们实际上不太在乎确定性，发包快就行了，不必指定哪个会话用哪个发送队列。

   2. 用准确性换时间（*Trade accuracy for time*）

      - 交换机负载均衡（*Switch load balancing*）

        > 不懂为什么会失去准确性……并且也没搜到这是个啥，只有 [Load-balanced switch](https://en.wikipedia.org/wiki/Load-balanced_switch)。

   3. 将计算变为空间（*Shift computation in space*）

      - [IPv6 分片](https://en.wikipedia.org/wiki/IP_fragmentation)（*IPv6 fragmentation*）

        > 这个原则的翻译我不好说，关于 IPv6 分片的事情可以看看[皮鞋哥](https://blog.csdn.net/dog250/article/details/88308917)。IPv6 禁止中间节点设备对 IP 报文进行分片，分片只能在端到端进行。中间设备只管转发就行了，不需要进行计算，但是这样空间就上去了。关于这个应该指的是用空间换时间，但是对不上原则 2.，所以就原样翻译了。这里的空间不指内存，而是指报文长度。

4. 充分利用系统组件（*Leverage off system components*）

   1. 利用局部性（*Exploit locality*）

      - 局部性驱动的接收器（*Locality-driven receiver*）

        > 我先猜一个空间局部性，C 语言黑魔法系列又来了。但是关于这个接收器是啥搜不到……

   2. 用空间换时间（*Trade memory for speed*）

      - [Luleå algorithm](https://en.wikipedia.org/wiki/Lule%C3%A5_algorithm)（*Processing; Lulea IP lookups*）

        > 可能是打错了，这里应该指的是这种 IP 查询的算法。看上去主要用压缩 Trie 实现的。并且这里是真正的算法里说的用空间换时间，和原则 3.3. 是不同意思的。

   3. 使用已有的硬件（*Exploit existing hardware*）

      - [快速 TCP 校验和](https://learn.microsoft.com/en-us/windows-server/networking/technologies/hpn/hpn-hardware-only-features#address-checksum-offload)（*Fast TCP checksum*）

        > 意思是把 TCP 算校验和交给网卡去做，能省 CPU 时间。

5. 添加硬件（*Add hardware*）

   > 这里书里可能有 typo，hardware 多了一个 g，第一条的 pipelining 少了一个 g。

   1. 使用内存交叉存取和管线化（*Use memory interleaving and pipelining*）

      - 管线化的 IP 查询（*Pipelined IP lookups*）

        > 倒是有[论文](https://link.springer.com/content/pdf/10.1007/978-3-642-03700-9_16.pdf)，但是没看出来用了什么新硬件，倒是设计了一个 bitmap。

   2. 使用宽字并行（*Use wide word parallelism*）

      - 共享内存交换机（*Shared memory switches*）

        > 这是啥玩意……

   3. 有效结合 DRAM 和 SRAM（*Combine DRAM and SRAM effectively*）

      - 维护计数器（*Maintaining counters*）

        > 因为 DRAM 和 SRAM 的速度和造价有很大差别。DRAM 造价低，但是存储速度慢，SRAM 造价高，存储速度快。相关问题复习计组，小丑竟是我自己。

6. 创建高效专用过程（*Create efficient specialized routines*）

   - UDP 校验和（*UDP checksums*）

     > UDP 校验和与 TCP 校验和计算方法是类似的，TCP 校验和链接里也说了可以算 UDP 校验和，不太明白为啥单挑这个例子讲。

7. 避免不必要抽象（*Avoid unnecessary generality*）
   - [Fbufs](https://dl.acm.org/doi/10.1145/173668.168634)

8. 不要被参考实现束缚（*Don't be tied to reference implementation*）
   - [Upcalls](https://dl.acm.org/doi/10.1145/323647.323645)

9. 在层接口中传递提示（*Pass hints in layer interfaces*）
   - 包过滤器（*Packet filters*）

10. 在协议头传递提示（*Pass hints in protocol headers*）

    - 标签交换（*Tag switching*）

      > 可能指的是 MPLS

11. 优化期望的情况（*Optimize the expected case*）

    - 头部预测（*Header prediction*）

      > [RFC 1185](https://www.rfc-editor.org/rfc/rfc1185) 的 2.3.2. 点提到了，但是里面引用的论文找不到了。

    1. 使用缓存（*Use caches*）
       - Fbufs

12. 添加状态以提升速度（*Add state for speed*）

    - 活跃虚电路列表（*Active VC list*）

      > 互联网上好像就没这个词一样……

    1. 增量计算（*Compute incrementally*）

       - 重新计算 CRC（*Recomputing CRCs*）

         > CRC 是可以增量计算的，后续的影响可以直接补到前面，不需要重复算以前的部分。

13. 优化自由度（*Optimize degrees of freedom*）
    - Trie 上的 IP 查询（*IP trie lookups*）

14. 使用桶排和位图（*Use bucket sorting, bitmaps*）
    - 时间轮（*Timing wheels*）

15. 建立高效的数据结构（*Create efficient data structures*）
    - 四层交换（*Level-4 switching*）

## 第一部分：游戏规则

### 第一章 网络算法学简介

网络算法学和传统算法不同，网络算法学认识到采取跨学科的系统方法来优化网络实现这一要点，而不是只用优化算法就好了。

网络算法学涉及操作系统（加速服务器），硬件设计（加速如路由器的网络设备）和算法设计（设计可扩展的算法），并且是一个系统方法。

网络算法学解决的问题是基础网络性能瓶颈，网络算法学所倡导的解决方案是一套解决这些瓶颈的基本技术。

#### 问题：网络瓶颈

本书的核心问题是如何让网络易用的同时实现裸硬件的性能。易用来自于强大的网络抽象，比如 socket 接口和基于前缀转发。但是如果不小心实现的话，这种抽象会产生比直接用光缆传更大的性能开销。

为了研究这个 gap，我们需要考虑两种网络设备：终端（*endnodes*）和路由器（*routers*）。

##### 终端瓶颈

终端包括 PC 和服务器，总之是网络的终端节点。终端是专门针对计算的，而不是网络，通常被设计为支持通用计算。因此终端瓶颈有两个主要原因：结构和规模。

- 结构（*Structure*）：为了运行任意代码，终端机的操作系统通常作为程序和硬件的媒介。OS 通常是分层的（比如有 HAL，资源管理层等等）；OS 实现了一些保护机制（*protection mechanisms*），以防应用程序破坏；最后，核心 OS 进程（也就是内核态），比如调度器和内存分配器是用通用机制（*general mechanisms*）写的，这个机制面向尽可能广泛的程序。但是 OS 分层，保护机制和过度抽象可能严重拖慢网络程序，即使在最快的处理器上跑也会很慢。
- 规模（*Scale*）：提供 Web 和其他服务的大服务器的出现导致了更深远的性能问题。比如 C10K，C10M 等问题。许多 OS 使用了低效的数据结构和算法，因为这些数据结构和算法是为连接数很少的时候设计的，太老了。

> 操作系统的结构和用户规模分别为内因和外因，同时制约网络性能。

我们将这些问题总结一下，如下表所示。

![](/images/network-algorithmics/f.1.1.png)

##### 路由器瓶颈

路由器是针对网络环境设计的，因此结构的 overhead 很小，OS 十分轻量并且专为路由器定制，很多东西都用硬件实现。取代结构，路由器瓶颈有两个主要原因：规模和服务。

- 规模（*Scale*）：同样有两方面规模
  - 带宽规模（*bandwidth scaling*）：光缆的传输速率越来越大，并且新应用程序越来越多，Internet 上的流量也越来越大了；
  - 网络规模（*population scaling*）：终端越来越多了。
- 服务（*Services*）：Internet 提供的服务越来越多，提供网络保障（*network guarantees*）变得十分重要——拥塞中时延保障，安全保障和故障发生时的可用性保障。

问题总结如下表所示。

![](/images/network-algorithmics/f.1.2.png)

#### 技术：网络算法学

当人们认识到 Internet 是一个由路由器和链路组成的系统时，可能就忽视了每个网络设备，比如从思科的 GSR（是思科的一款骨干网路由器）到 Apache 网络服务器都是系统。系统是由相互关联的子系统构建而成的，这些子系统在不同的时间点上被实例化。比如，一个核心路由器由带有转发引擎的[线卡](https://en.wikipedia.org/wiki/Line_card)和被纵横式交换机连接的数据包内存组成。路由器的行为受到各种时间的影响，其范围从制造时间（当默认参数存储在 [NVRAM](https://en.wikipedia.org/wiki/Non-volatile_random-access_memory) 中时）到路由计算时间（当路由器协商计算路由时）到数据包转发时间（当数据包被发送到相邻的路由器时）。

> 事物是普遍联系的。

因此用系统方法的一个重要的观察是通常可以通过在空间上（即在其他子系统上）或在时间上（即在明显需要该功能之前或之后的时间点上）移动它的一些功能来设计一个有效的子系统。

> 这句话完全没有理解什么是在时间或空间上移动功能。原文如下：
>
> Thus one key observation in the systems approach is that one can often design an efficient subsystem by moving some of its functions in space (i.e., to other subsystems) or in time (i.e., to points in time before or after the function is apparently required).

从某种意义上说，网络算法学的实践者是一个不择手段的机会主义者，愿意在任何时候改变规则以使游戏更容易。唯一的约束是整个系统所提供的功能要继续满足用户。

> 解决不了问题就换个问题，这是对的。解决问题可以用技巧，但是也可以靠力量。

考虑网络实现者在高速网络下面对的限制——越来越复杂的任务，需要支持更大的系统，小容量的高速内存和更少的内存访问次数——可能需要用尽实现技巧去跟上互联网日益增长的速度和规模。但是设计者可以直接加硬件，改变系统假设，设计一个新算法——反正任务是完成了。

#### 热身训练：鉴别恶意数据包

> 这节书里是在上一节之下的，但是后续跟它同级的内容都从属与它，所以单将其设置为一个大标题，后续内容作为这一节下的内容。

考虑一个前端网络监视器（就当它是个防火墙吧），要设计一个标记入流量中的可疑包——这种包可能进行缓冲区溢出攻击，攻击者在网络头部 $F$ 中放入机器码 $C$。

> 上学期刚做完缓冲区溢出实验这回又要防……

攻击主要原理就是缓冲区溢出导致注入的机器码（也可以是 shellcode）被执行。

> 其实未必要在防火墙层面上防，直接在设备上防开销已经不大了。

具体检查和防范的方法是，检测 URL 里包含的字符，因为要利用这个问题，势必 URL 会很长，并且大部分都是特殊符号（毕竟 shellcode 中大部分字符需要转成 URL 编码），比如 `#`。因此防火墙可以拦下这类包再进行检查。

当然有可能一些 CGI 脚本会被拦下，导致假阳性（*false positive*）的情况出现，因此我们假设有一个由安全工程师设计的规范被交给了芯片工程师。

这个例子是由 Mike Fisk 提出的问题。在面对这个问题时，我们从[稻草人设计](https://www.techopedia.com/definition/14585/straw-man)开始，一步一步优化这个设计，展示网络算法学的原则和技巧。

##### 直观方案

芯片维护两个字符类型数组 $T$ 和 $C$，每个数组的长度都是 $256$。门限数组 $T$ 包含每个字符可接受的百分比（也就是这种字符个数占全 URL 长度的最大占比）。如果某种字符的出现频率比这个值大，就说明这个包有问题。每个字符的门限限制可能不同。

$C$ 记录每个字符出现多少次，不想过多解释了。

所以整个算法过程就可以描述出来了。先扫一遍 URL，可以得到 $C$ 数组和字符串长度 $L$。然后对于每种字符，如果存在 $C_i\ge L\cdot T_i$，那么就把这个包标记可疑，否则放行。那么这个算法就是线性的，反正就扫扫完事了。

假设数据包高速进入路由器，我们希望在下一个数据包到达前把这个数据包处理完，这个要求叫线速处理（*wire-speed processing*），这个要求在网络中很常见，即使在最坏的情况下，它也能防止处理工作的积压。为了满足线速，理想的芯片设计需要对于每个 URL 中的字节做尽可能少的处理。假设主要步骤中一次自增操作可以在收到一字节之前完成。

> 因为自增操作十分快，收到一字节需要进行信号转换，但是自增操作过 CPU 的速度几乎是瞬间的。

但是这个方案中，我们扫了两次数组，首先对数组清零，然后检查是否超过门限限制。最小的数据包大小经常大概 $40$ 字节，并且仅包括网络头部。加上 $768$ 次操作（对 $C$ 中的每个元素的一次读，一次写和对 $T$ 数组所有元素的一次读），这个设计是不可接受的。

##### 想想算法

直观的说，第二次扫 $C$ 和 $T$ 是浪费的。比如，如果扫到一个字符超过限制了，直接返回就完事了，也就是常说的扫不满。这暗示了我们只需要维护出现次数的最大值就好了。但是这个方法是错的，因为在动态变化中不满足局部最优解是全局最优解，不能贪。

聪明的读者一定发现了，我们要判断的东西 $C_i\ge L\cdot T_i$ 这个不等式两端都有 $i$，但是我们换个形式：$\frac{C_i}{T_i}\ge L$，这样只有一端有 $i$ 了。实际上我们只需要维护 $\frac{C_i}{T_i}$ 的最大值即可。因为 $T_i$ 是常数，$C_i$ 自增，所以直接维护这个分式的最大值即可。正确性蕴含自之前的描述。

这样我们砍掉了第二次扫描，虽然操作次数没变，但是我们还是砍掉了一次扫描。

> 到这里的思路是非常正常的，下面就是黑魔法时间了。

##### 细化算法：利用硬件

我们优化了一次扫描，但是引入了除法。众所周知除法的电路逻辑十分复杂，算一次除法的周期比算加法长得多，我们怎么优化呢？

首先我们可以干掉浮点数，比如 $2.78\%$ 和 $3\%$ 差不多，那么门限百分比里的所有数都可以 round 到一个离它最近的整数上。那么既然都变成 $3\%$ 了，为什么不搞成 $\frac{1}{x}$ 这种形式呢，用百分数算完整数除法之后最后还得乘 $100$，用 $\frac{1}{x}$ 只需要乘 $x$。并且这个 $x$ 最好是 $2$ 的整数次幂，毕竟这样只需要移位就可以实现乘法操作了。

> 这里每一次转化都很合理，但是放在一起可能有些不可理喻，但这就是黑魔法。

因此逻辑电路只需要实现移位和比较电路就可以了。状态存储只需要一个寄存器存 $\frac{C_i}{T_i}$ 的最大值，但是还是没有优化读取和写入的操作次数。

最快的芯片内部存储需要 1 到 2 纳秒读一次，但是更慢的内存可能需要 10 纳秒左右——这比逻辑电路计算的时间要慢。单门延迟在皮秒量级内，位移逻辑的门延迟时间并不高。所以瓶颈在内存访问上。

我们可以把 $C$ 和 $T$ 两个数组合并成一个数组来减少内存访问，让两次读变成一次读。这是一个压位技巧，$C$ 数组是整数数组，每个整数设计为 $15$ 位长（这样可以处理不超过 32K 的数据包，考虑极限情况），$T$ 数组为了精度，每个整数设计为 $14$ 位长。因此这两个数组就被合成一个了，每个元素的位长为 $29$。实践上，硬件可以处理长达 $1000$ 位的宽字。同样的，把这两个数组分开也很简单，位操作一下就可以了。

> 因为位操作比访存快，所以我们确实可以优化速度。

##### 清理

说实话到这儿确实看起来不错，但是我们忘了一个最棘手的问题：我们忘了初始化 $C$ 数组。

初始化最大值为 $0$ 是对寄存器操作，这个操作是很快的，但是初始化 $C$ 数组又需要访存，我们不能承受这个访存时间。

这时我们可以考虑惰性计算，反正我只关心 $C$ 数组中跟这次计算有关的字符，无关的字符可以不用动。那么考虑记录一个 $3$ 位的版本号 $G$，每次需要自增一个 $C_i$ 时，先判断这个位置的版本号是否与当前包版本号相同，如果不同的话意味着这个位置要被初始化，并且是这个版本第一次访问到，因此需要置 $G_i$ 为数据包当前版本号，并初始化 $C_i$ 为 $1$，否则 $C_i$ 自增。之后的更新最大值操作仍然如同之前。

> 维护版本号并进行惰性初始化维护也很常见于各种算法竞赛的题目中，通常就是对一个很长的数组初始化很少的位置，直接 for 过去铁超时，所以用这种初始化。

由于版本号只是一个 $3$ 位的整数，因此可以想见这个版本号是在模 $8$ 意义下的，所以可以看成一种 Hash，可能出现版本号冲突，这样初始化就没有依据了。

这里考虑芯片设计中加入一个「擦除」循环，循环中读取这个数组，并且初始化所有过期的版本号。为了正确性，芯片必须保证在每八个数据包处理完之后进行这样的一次完整循环。考虑如果每个包有 $40$ 个非 URL 字节（除了 URL 之外有 $40$ 字节），八个包就是 $320$ 个，$320>256$，这段时间可以让数组的每个元素都被访问一次（读一次和写一次）。当然，这个非 URL 字节数是估计的，设计者真正可以获得的这个数值更大，通过增大版本号可以充分利用非 URL 字符产生的间隙，但是这样数组存储的空间就会增大。

> 这里有个假设，就是数据包都要过内存，也就是数据包要先存在内存里然后再被读取发出去。如果直接电路交换出去了，这个均摊是不成立的。但是应该确实所有包都要过内存的，毕竟要过转发队列的。
>
> 其实最简单的一种实现方式是：处理 8 个包后，芯片直接进入擦除态，这段时间里去访存擦除，但是这样是会形成时间毛刺的，这段时间没法处理包，虽然从数学意义上均摊了，但是不符合需要达到线速的要求。我们要把这段时间实际均摊到擦除过程中，而不是数学意义上。

那么芯片有两个状态：一个是处理 URL 的，一个是处理非 URL 的。当 URL 全部处理完后，芯片进入擦除态。芯片需要再维护一个寄存器 $s$ 表示下一个要擦除数组的哪个位置，当接收到一个非 URL 字节时，芯片判断如果 $G_s\neq g$（$g$ 为当前版本号），那么 $G_s$ 被置为 $g$，$C_s$ 置为 $0$。

> 我们可以保证每 8 个包经过后每个位置都被这样重置一遍，所以每个位置记录的 $G_i$ 可以认为都属于同一批 8 个包之内的，正确性是有保证的。

这样，我们用了 $32$ 位（$3$ 位 $G_i$，$15$ 位 $C_i$ 和 $14$ 位 $T_i$ 压一起）元素，长为 $256$ 个元素的数组就完成了这个操作，同时我们需要维护一个当前版本号 $g$，一个下一次要擦除的位置 $s$ 和 URL 长度 $L$，这些变量只需要用三个寄存器就可以维护了，代价很小。

> 黑魔法部分终于结束了。

#### 网络算法学的特点

- 网络算法学是跨学科的
  - 跨学科的思维有助于产生出最好的设计

- 网络算法学认识到了系统思维的重要性

  - 放宽要求（把门限百分比变成 $2$ 的幂次）和将工作从一个子系统迁移到另一个子系统是极其常见的系统技术，但是教学上不教

    > 这玩意过于 tricky 了，当然不会教。

  - 「黑盒思维」不利于产生出整体或系统思维

    > 毕竟我们在优化这个黑盒。

- 网络算法学从算法思维中获益

  > 有一说一算法部分到变换到 $\frac{C_i}{T_i}$ 的地方就停了，剩下的都是黑魔法，并且一般来说，这种变换也不叫新算法，算法中的 trick 罢了。

#### 网络算法学的定义

> Network algorithmics is the use of an interdisciplinary systems approach, seasoned with algorithmic thinking, to design fast implementations of network processing tasks at servers, routers, and other networking devices.

网络算法学运用跨学科的、系统的方法加上算法思维，为服务器、路由器和其它网络设备上的网络处理任务设计快速的实现。

> 上述中文定义摘抄自中科大网络算法学课件。

#### 练习

设计一个卡方检验的有效实现。也就是计算
$$
\sum_{i=1}^n\frac{(f_i-a_i)^2}{f_i}
$$
其中 $f_i$ 是预期频率，$a_i$ 是实际观察到的频率。如果这个值比一个门限值大，就需要告警。假设你只能在结尾获得长度（还是那个 URL 检测的例子）。

> 实际上还是一个路子，只不过上面变平方了需要化简
> $$
> \sum_{i=1}^n\frac{(f_i-a_i)^2}{f_i}=\frac{1}{L}\sum_{i=1}^n\frac{(T_i-C_i)^2}{T_i}\ge P
> $$
> 其中 $L$ 是长度，$P$ 是门限。$T_i$ 是预期次数，$C_i$ 为实际次数。
>
> 然后接着拆
> $$
> \frac{1}{L}\sum_{i=1}^n\frac{(T_i-C_i)^2}{T_i}=\frac{1}{L}\sum_{i=1}^nT_i-2C_i+\frac{C_i^2}{T_i}\ge P
> $$
> 常数挪右边去，不等式变为
> $$
> \sum_{i=1}^n \frac{C_i^2}{T_i}-2\sum_{i=1}^n C_i\ge PL-\sum_{i=1}^n T_i
> $$
> 考虑我们维护的是左边部分的和，$C_i$ 每自增 $1$，对左边和式的贡献是 $\frac{2C_i+1}{T_i}-2=\frac{2(C_i-T_i)+1}{T_i}$，所以就差不多一样维护就行了，每次对和加上这个贡献。只不过这个题里维护和，例子里维护最大值，并且设计时需要考虑整数是带符号的，需要设计有符号除法移位。
